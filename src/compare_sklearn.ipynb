{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X: np.ndarray  # input\n",
    "y: np.ndarray  # target\n",
    "\n",
    "# Load data from https://www.openml.org/search?type=data&sort=runs&id=554   \n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    " \n",
    "# MNIST: dataset of 28x28 pixel images of handwritten digits (0-9)\n",
    "# Input: vector of 784 pixels (28x28)\n",
    "# Target: number 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use only 1000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X[:1000], y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], shape=(1000, 784)),\n",
       " array(['5', '0', '4', '1', '9', '2', '1', '3', '1', '4', '3', '5', '3',\n",
       "        '6', '1', '7', '2', '8', '6', '9', '4', '0', '9', '1', '1', '2',\n",
       "        '4', '3', '2', '7', '3', '8', '6', '9', '0', '5', '6', '0', '7',\n",
       "        '6', '1', '8', '7', '9', '3', '9', '8', '5', '9', '3', '3', '0',\n",
       "        '7', '4', '9', '8', '0', '9', '4', '1', '4', '4', '6', '0', '4',\n",
       "        '5', '6', '1', '0', '0', '1', '7', '1', '6', '3', '0', '2', '1',\n",
       "        '1', '7', '9', '0', '2', '6', '7', '8', '3', '9', '0', '4', '6',\n",
       "        '7', '4', '6', '8', '0', '7', '8', '3', '1', '5', '7', '1', '7',\n",
       "        '1', '1', '6', '3', '0', '2', '9', '3', '1', '1', '0', '4', '9',\n",
       "        '2', '0', '0', '2', '0', '2', '7', '1', '8', '6', '4', '1', '6',\n",
       "        '3', '4', '5', '9', '1', '3', '3', '8', '5', '4', '7', '7', '4',\n",
       "        '2', '8', '5', '8', '6', '7', '3', '4', '6', '1', '9', '9', '6',\n",
       "        '0', '3', '7', '2', '8', '2', '9', '4', '4', '6', '4', '9', '7',\n",
       "        '0', '9', '2', '9', '5', '1', '5', '9', '1', '2', '3', '2', '3',\n",
       "        '5', '9', '1', '7', '6', '2', '8', '2', '2', '5', '0', '7', '4',\n",
       "        '9', '7', '8', '3', '2', '1', '1', '8', '3', '6', '1', '0', '3',\n",
       "        '1', '0', '0', '1', '7', '2', '7', '3', '0', '4', '6', '5', '2',\n",
       "        '6', '4', '7', '1', '8', '9', '9', '3', '0', '7', '1', '0', '2',\n",
       "        '0', '3', '5', '4', '6', '5', '8', '6', '3', '7', '5', '8', '0',\n",
       "        '9', '1', '0', '3', '1', '2', '2', '3', '3', '6', '4', '7', '5',\n",
       "        '0', '6', '2', '7', '9', '8', '5', '9', '2', '1', '1', '4', '4',\n",
       "        '5', '6', '4', '1', '2', '5', '3', '9', '3', '9', '0', '5', '9',\n",
       "        '6', '5', '7', '4', '1', '3', '4', '0', '4', '8', '0', '4', '3',\n",
       "        '6', '8', '7', '6', '0', '9', '7', '5', '7', '2', '1', '1', '6',\n",
       "        '8', '9', '4', '1', '5', '2', '2', '9', '0', '3', '9', '6', '7',\n",
       "        '2', '0', '3', '5', '4', '3', '6', '5', '8', '9', '5', '4', '7',\n",
       "        '4', '2', '7', '3', '4', '8', '9', '1', '9', '2', '8', '7', '9',\n",
       "        '1', '8', '7', '4', '1', '3', '1', '1', '0', '2', '3', '9', '4',\n",
       "        '9', '2', '1', '6', '8', '4', '7', '7', '4', '4', '9', '2', '5',\n",
       "        '7', '2', '4', '4', '2', '1', '9', '7', '2', '8', '7', '6', '9',\n",
       "        '2', '2', '3', '8', '1', '6', '5', '1', '1', '0', '2', '6', '4',\n",
       "        '5', '8', '3', '1', '5', '1', '9', '2', '7', '4', '4', '4', '8',\n",
       "        '1', '5', '8', '9', '5', '6', '7', '9', '9', '3', '7', '0', '9',\n",
       "        '0', '6', '6', '2', '3', '9', '0', '7', '5', '4', '8', '0', '9',\n",
       "        '4', '1', '2', '8', '7', '1', '2', '6', '1', '0', '3', '0', '1',\n",
       "        '1', '8', '2', '0', '3', '9', '4', '0', '5', '0', '6', '1', '7',\n",
       "        '7', '8', '1', '9', '2', '0', '5', '1', '2', '2', '7', '3', '5',\n",
       "        '4', '9', '7', '1', '8', '3', '9', '6', '0', '3', '1', '1', '2',\n",
       "        '6', '3', '5', '7', '6', '8', '3', '9', '5', '8', '5', '7', '6',\n",
       "        '1', '1', '3', '1', '7', '5', '5', '5', '2', '5', '8', '7', '0',\n",
       "        '9', '7', '7', '5', '0', '9', '0', '0', '8', '9', '2', '4', '8',\n",
       "        '1', '6', '1', '6', '5', '1', '8', '3', '4', '0', '5', '5', '8',\n",
       "        '3', '6', '2', '3', '9', '2', '1', '1', '5', '2', '1', '3', '2',\n",
       "        '8', '7', '3', '7', '2', '4', '6', '9', '7', '2', '4', '2', '8',\n",
       "        '1', '1', '3', '8', '4', '0', '6', '5', '9', '3', '0', '9', '2',\n",
       "        '4', '7', '1', '2', '9', '4', '2', '6', '1', '8', '9', '0', '6',\n",
       "        '6', '7', '9', '9', '8', '0', '1', '4', '4', '6', '7', '1', '5',\n",
       "        '7', '0', '3', '5', '8', '4', '7', '1', '2', '5', '9', '5', '6',\n",
       "        '7', '5', '9', '8', '8', '3', '6', '9', '7', '0', '7', '5', '7',\n",
       "        '1', '1', '0', '7', '9', '2', '3', '7', '3', '2', '4', '1', '6',\n",
       "        '2', '7', '5', '5', '7', '4', '0', '2', '6', '3', '6', '4', '0',\n",
       "        '4', '2', '6', '0', '0', '0', '0', '3', '1', '6', '2', '2', '3',\n",
       "        '1', '4', '1', '5', '4', '6', '4', '7', '2', '8', '7', '9', '2',\n",
       "        '0', '5', '1', '4', '2', '8', '3', '2', '4', '1', '5', '4', '6',\n",
       "        '0', '7', '9', '8', '4', '9', '8', '0', '1', '1', '0', '2', '2',\n",
       "        '3', '2', '4', '4', '5', '8', '6', '5', '7', '7', '8', '8', '9',\n",
       "        '7', '4', '7', '3', '2', '0', '8', '6', '8', '6', '1', '6', '8',\n",
       "        '9', '4', '0', '9', '0', '4', '1', '5', '4', '7', '5', '3', '7',\n",
       "        '4', '9', '8', '5', '8', '6', '3', '8', '6', '9', '9', '1', '8',\n",
       "        '3', '5', '8', '6', '5', '9', '7', '2', '5', '0', '8', '5', '1',\n",
       "        '1', '0', '9', '1', '8', '6', '7', '0', '9', '3', '0', '8', '8',\n",
       "        '9', '6', '7', '8', '4', '7', '5', '9', '2', '6', '7', '4', '5',\n",
       "        '9', '2', '3', '1', '6', '3', '9', '2', '2', '5', '6', '8', '0',\n",
       "        '7', '7', '1', '9', '8', '7', '0', '9', '9', '4', '6', '2', '8',\n",
       "        '5', '1', '4', '1', '5', '5', '1', '7', '3', '6', '4', '3', '2',\n",
       "        '5', '6', '4', '4', '0', '4', '4', '6', '7', '2', '4', '3', '3',\n",
       "        '8', '0', '0', '3', '2', '2', '9', '8', '2', '3', '7', '0', '1',\n",
       "        '1', '0', '2', '3', '3', '8', '4', '3', '5', '7', '6', '4', '7',\n",
       "        '7', '8', '5', '9', '7', '0', '3', '1', '6', '2', '4', '3', '4',\n",
       "        '4', '7', '5', '9', '6', '9', '0', '7', '1', '4', '2', '7', '3',\n",
       "        '6', '7', '5', '8', '4', '5', '5', '2', '7', '1', '1', '5', '6',\n",
       "        '8', '5', '8', '4', '0', '7', '9', '9', '2', '9', '7', '7', '8',\n",
       "        '7', '4', '2', '6', '9', '1', '7', '0', '6', '4', '2', '5', '7',\n",
       "        '0', '7', '1', '0', '3', '7', '6', '5', '0', '6', '1', '5', '1',\n",
       "        '7', '8', '5', '0', '3', '4', '7', '7', '5', '7', '8', '6', '9',\n",
       "        '3', '8', '6', '1', '0', '9', '7', '1', '3', '0', '5', '6', '4',\n",
       "        '4', '2', '4', '4', '3', '1', '7', '7', '6', '0', '3', '6'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onehot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(X):\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    one_hot_encoded = encoder.fit_transform(X)\n",
    "    return one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_encoded = one_hot_encode(y)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the src directory\n",
    "sys.path.append(os.path.abspath('../')) \n",
    "\n",
    "from model.ffnn import FFNN\n",
    "from graph.visualize import Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Effect of Regularization\n",
    "\n",
    "All model uses the same settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) No Regularizationn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feed Forward Neural Network\n",
       "> Layers: [784, 8, 4, 10]\n",
       "> MLP of 3 Layers [\n",
       "\tLayer(label=Hidden-Layer-1, neurons=[\n",
       "\tNeuron(nin=784, activation=sigmoid, label=Hidden-Layer-1_N1)\n",
       "\tNeuron(nin=784, activation=sigmoid, label=Hidden-Layer-1_N2)\n",
       "\tNeuron(nin=784, activation=sigmoid, label=Hidden-Layer-1_N3)\n",
       "\tNeuron(nin=784, activation=sigmoid, label=Hidden-Layer-1_N4)\n",
       "\tNeuron(nin=784, activation=sigmoid, label=Hidden-Layer-1_N5)\n",
       "\tNeuron(nin=784, activation=sigmoid, label=Hidden-Layer-1_N6)\n",
       "\tNeuron(nin=784, activation=sigmoid, label=Hidden-Layer-1_N7)\n",
       "\tNeuron(nin=784, activation=sigmoid, label=Hidden-Layer-1_N8)])\n",
       "\tLayer(label=Hidden-Layer-2, neurons=[\n",
       "\tNeuron(nin=8, activation=sigmoid, label=Hidden-Layer-2_N1)\n",
       "\tNeuron(nin=8, activation=sigmoid, label=Hidden-Layer-2_N2)\n",
       "\tNeuron(nin=8, activation=sigmoid, label=Hidden-Layer-2_N3)\n",
       "\tNeuron(nin=8, activation=sigmoid, label=Hidden-Layer-2_N4)])\n",
       "\tLayer(label=Output-Layer, neurons=[\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N1)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N2)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N3)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N4)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N5)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N6)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N7)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N8)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N9)\n",
       "\tNeuron(nin=4, activation=sigmoid, label=Output-Layer_N10)])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn = FFNN([784, 8, 4, 10], loss=\"mse\", active=[\"sigmoid\", \"sigmoid\", \"sigmoid\"], seed=69, weight=\"normal\", mean=0.5, variance=1, regularization=\"none\")\n",
    "ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [03:11<12:46, 191.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6598459096623419\n",
      "Validation Loss: 0.6596706810826491\n",
      "\n",
      "Starting Epoch 1\n"
     ]
    }
   ],
   "source": [
    "lossReal, lossReal_history = ffnn.training(X, y_encoded, 20, 0.01, 5, 1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizer.plot_loss_history(lossReal_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=69)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(8, 4),  \n",
    "    activation=\"logistic\",     \n",
    "    solver=\"adam\",              \n",
    "    alpha=0.0,                  \n",
    "    random_state=69,            \n",
    "    max_iter=200,              \n",
    "    verbose=True,               \n",
    ")\n",
    "\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "training_loss = mlp.loss_curve_\n",
    "\n",
    "\n",
    "validation_loss = []\n",
    "for epoch in range(len(training_loss)):\n",
    "    y_val_pred_proba = mlp.predict_proba(X_val)  \n",
    "    val_loss = log_loss(y_val, y_val_pred_proba)  \n",
    "    validation_loss.append(val_loss)\n",
    "\n",
    "# Plot training vs validation loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(training_loss, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(validation_loss, label=\"Validation Loss\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss (Sigmoid Activation)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Final accuracy\n",
    "y_pred = np.argmax(mlp.predict_proba(X_val), axis=1)  \n",
    "y_val_labels = np.argmax(y_val, axis=1)\n",
    "accuracy = accuracy_score(y_val_labels, y_pred)\n",
    "print(f\"Final Validation Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
